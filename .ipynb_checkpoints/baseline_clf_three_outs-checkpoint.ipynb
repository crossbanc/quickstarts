{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": "49808de5340c4f02abfca1df187f9d6e",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 982,
    "execution_start": 1704561827643,
    "is_code_hidden": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.covariance import OAS\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "ef381fc286004121b94d726294f9ad17",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1704561828660,
    "is_code_hidden": false,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "#H0: Simpler models tend to outperform more complex models \n",
    "#H1: Models using factually relevant data tend to outperform\n",
    "\n",
    "def train_model(setname, data_frame, target_col=\"y\", folds=3):\n",
    "\n",
    "    OA = OAS(store_precision=False, assume_centered=False)\n",
    "    classifiers = {\n",
    "\n",
    "        'SGR': StackingClassifier(estimators=[('gbc', GradientBoostingClassifier()), ('rc', RidgeClassifier())], \n",
    "                                  final_estimator=SVC()),\n",
    "        'SAG': StackingClassifier(estimators=[('ada', AdaBoostClassifier()), ('gnb', GaussianNB())], \n",
    "                                  final_estimator=SVC()),\n",
    "        \n",
    "        'BRF': BaggingClassifier(RandomForestClassifier(), n_estimators=10, random_state=232),\n",
    "        'OAS': LinearDiscriminantAnalysis(solver=\"lsqr\", covariance_estimator=OA), \n",
    "        'PAC': CalibratedClassifierCV(PassiveAggressiveClassifier(), cv=folds), \n",
    "\n",
    "        #Below 80%\n",
    "        'BSC': BaggingClassifier(SGDClassifier(), n_estimators=10, random_state=232),\n",
    "        'BlC': BaggingClassifier(SGDClassifier(loss=\"log_loss\"), n_estimators=10, random_state=232),\n",
    "        \n",
    "        # Your Model(s) - Do not overfit and do K.I.S.S the environment.\n",
    "        #1\n",
    "        #2\n",
    "        #3\n",
    "        \n",
    "    }\n",
    "\n",
    "    x = data_frame.copy().drop(columns=[target_col]) \n",
    "    y = data_frame[target_col]\n",
    "    \n",
    "    \n",
    "    # Upsample minority class\n",
    "    if len(df_minority_1) > 20:\n",
    "        df_minority_1_upsampled = resample(df_minority_1, replace=True, n_samples=len(df_majority), random_state=232)\n",
    "    else:\n",
    "        # Monte Carlo fallacy \n",
    "        df_minority_1_upsampled = pd.DataFrame() \n",
    "\n",
    "\n",
    "    # Upsample alternative minority class\n",
    "    if len(df_minority_4) > 20:\n",
    "        df_minority_4_upsampled = resample(df_minority_1, replace=True, n_samples=len(df_majority), random_state=232) \n",
    "    else:\n",
    "        # Monte Carlo fallacy \n",
    "        df_minority_4_upsampled = pd.DataFrame()    \n",
    " \n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    data_frame_upsampled = pd.concat([df_majority, df_minority_1_upsampled, df_minority_4_upsampled])\n",
    "    x = data_frame_upsampled.copy().drop(columns=[target_col]) \n",
    "    y = data_frame_upsampled[target_col]\n",
    "\n",
    "\n",
    "    #Confirmed balanced Dataset\n",
    "    #counter = Counter(y)\n",
    "    #print(counter)\n",
    "    #print(\" \")\n",
    "    #print(\" \")\n",
    "    \n",
    "\n",
    "    # Create a correlation matrix\n",
    "    corr_matrix = x.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]    \n",
    "    # Drop highly correlated features from X\n",
    "    x = x.drop(x[to_drop], axis=1)\n",
    "\n",
    "    # total number of features\n",
    "    k = x.shape[1]\n",
    "    \n",
    "    best_features = []\n",
    "    best_scores = [] \n",
    "\n",
    "    for name, classifier in classifiers.items():\n",
    "        \n",
    "        classifier_pipeline = Pipeline([\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        best_k_score = 0\n",
    "        for k in range(1, k+1):\n",
    "            bestfeatures = SelectKBest(score_func=f_classif, k=k)\n",
    "            fit = bestfeatures.fit(x, y)\n",
    "\n",
    "            dfscores = pd.DataFrame(fit.scores_)\n",
    "            dfcolumns = pd.DataFrame(x.columns)\n",
    "                \n",
    "            # Concatenate dataframes for better visualization \n",
    "            featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "            featureScores.columns = ['Specs','Score']  \n",
    "                \n",
    "            # Select the features with the highest scores\n",
    "            best_features_name = featureScores.nlargest(k, 'Score')['Specs'].values\n",
    "            x_best = x[best_features_name]\n",
    "\n",
    "            # Apply cross-validation and calculate mean score for current classifier with \n",
    "            # the selected number of features\n",
    "            cv_score = cross_val_score(classifier_pipeline, x_best, y, cv=folds, scoring='accuracy').mean()\n",
    "                \n",
    "            # If the current score is better than the best_k_score, then update best_k_score \n",
    "            # and the final list of best features associated with the classifier\n",
    "            if cv_score > best_k_score:\n",
    "                best_k_score = cv_score\n",
    "                best_k_features_name = best_features_name\n",
    "                 \n",
    "        best_features_name = best_k_features_name    \n",
    "        best_features.append(best_features_name)\n",
    "        \n",
    "        x_best = x[best_features_name]\n",
    "        score = cross_val_score(classifier_pipeline, x_best, y, cv=folds, scoring='accuracy').mean()\n",
    "        best_scores.append(score)\n",
    "\n",
    "    best_classifier_index = np.argmax(best_scores)\n",
    "    best_classifier_name = list(classifiers.keys())[best_classifier_index]\n",
    "    best_feature_name = best_features[best_classifier_index]\n",
    "    best_score = best_scores[best_classifier_index]\n",
    "   \n",
    "    best_classifier = classifiers[best_classifier_name]\n",
    "    best_classifier_pipeline = Pipeline([\n",
    "        ('classifier', best_classifier)\n",
    "    ])\n",
    "    \n",
    "    best_classifier_pipeline.fit(x[best_feature_name], y)\n",
    "\n",
    "    # Save the model\n",
    "    filename = f\"./models/{setname}.joblib\"\n",
    "    dump(best_classifier_pipeline, filename)\n",
    "\n",
    "    return best_classifier_name, round(best_score, 4), best_feature_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": "24ebc645201b48178f65642acb379777",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1704561828712,
    "is_code_hidden": false,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# List of Dataset Names\n",
    "datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": "d53cf6121c134c2588be91e82230f18e",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1704561828727,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def use_data():\n",
    "    \n",
    "    selected = pd.DataFrame()\n",
    "    for setname in datasets:\n",
    "        \n",
    "        filename = f\"./datasets/{setname}.parquet\"        \n",
    "        existing_data = pd.read_parquet(filename)\n",
    "        \n",
    "        data = existing_data[['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6',\n",
    "        'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'y']]\n",
    "\n",
    "        bclf, score, features = train_model(setname, data)\n",
    "        selected = pd.concat([selected, pd.DataFrame([(setname, bclf, score, features)], \n",
    "        columns=['setname', 'classifier', 'score', 'features'])], ignore_index=True)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": "a5d362d25c40403b9449d84a96234e92",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 180085,
    "execution_start": 1704561828790,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "selection = use_data()\n",
    "selected = selection.sort_values(by=[\"score\"], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0cee38102c1b4e69b4a72928396d7446",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 236,
    "execution_start": 1704561457446,
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "filename = f\"./models/classifiers.csv\" \n",
    "selected.to_csv(filename)\n",
    "print(f\"Your CAS: {selected['score'].mean()}\")\n",
    "print(\" \")  \n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bb8bd6fe92584f138ff5947789b1e346",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 54,
    "execution_start": 1704561457679,
    "source_hash": null
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "8ee548ac5a9e4bcb94ebac097e9bea48",
  "deepnote_persisted_session": {
   "createdAt": "2024-01-05T09:30:26.848Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
